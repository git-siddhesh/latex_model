











































































































































































































































































































  1%|▍                                                 | 2000/224091 [10:03<16:51:54,  3.66it/s]
  0%|                                                       | 6/47459 [00:00<1:36:40,  8.18it/s]










































































































































































































































































































































































































































































































































































































































































































































































































































































































100%|███████████████████████████████████████████████████▉| 47424/47459 [29:21<00:01, 32.65it/s]
















































































































































































































































































































  2%|▊                                                | 4000/224091 [49:40<19:04:52,  3.20it/s]
  0%|                                                      | 6/47459 [00:00<1:36:48,  8.17it/s]







































































































































































































































































































































































































































































































































































































































































































































































































































































































100%|███████████████████████████████████████████████████▉| 47413/47459 [29:11<00:01, 27.83it/s]












































































































































































































































































































  3%|█▎                                             | 6000/224091 [1:28:54<17:00:49,  3.56it/s]
{'loss': 0.0, 'learning_rate': 0.0005989734359508614, 'epoch': 0.03}






























































































































































































































































































































































































































































































































































































  File "/home/dosisiddhesh/latex_model/script/v2_mp_mistral.py", line 346, in <module>
    train_result = trainer.train()
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/optimum/intel/openvino/trainer.py", line 678, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/optimum/intel/openvino/trainer.py", line 837, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/transformers/trainer.py", line 3095, in evaluate
    output = eval_loop(
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/transformers/trainer.py", line 3284, in evaluation_loop
    loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/transformers/trainer.py", line 3501, in prediction_step
    loss, outputs = self.compute_loss(model, inputs, return_outputs=True)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/optimum/intel/openvino/trainer.py", line 771, in compute_loss
    retval = super().compute_loss(model, inputs, return_outputs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/nncf/torch/dynamic_graph/wrappers.py", line 137, in wrapped
    return module_call(self, *args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 1154, in forward
    outputs = self.model(
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/nncf/torch/dynamic_graph/wrappers.py", line 137, in wrapped
    return module_call(self, *args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 1039, in forward
    layer_outputs = decoder_layer(
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/nncf/torch/dynamic_graph/wrappers.py", line 137, in wrapped
    return module_call(self, *args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 766, in forward
    hidden_states = self.post_attention_layernorm(hidden_states)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/nncf/torch/dynamic_graph/wrappers.py", line 137, in wrapped
    return module_call(self, *args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dosisiddhesh/miniconda3/envs/mist3_env/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 86, in forward
    variance = hidden_states.pow(2).mean(-1, keepdim=True)
KeyboardInterrupt